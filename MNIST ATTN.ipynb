{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNSIT RNN test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import timeit\n",
    "from torchnet import meter\n",
    "%matplotlib inline\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set_train = dset.MNIST(r'../MNIST', train=True, transform=T.ToTensor(), download=False)\n",
    "loader_train = DataLoader(set_train, batch_size=512)\n",
    "set_test = dset.MNIST(r'../MNIST', train=False, transform=T.ToTensor(),download=False)\n",
    "loader_test = DataLoader(set_test, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 看下大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小： torch.Size([60000, 28, 28])\n训练集标签： torch.Size([60000])\n测试集大小： torch.Size([10000, 28, 28])\n测试集标签： torch.Size([10000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"训练集大小：\",set_train.train_data.size())\n",
    "print(\"训练集标签：\",set_train.train_labels.size())\n",
    "print(\"测试集大小：\",set_test.test_data.size())\n",
    "print(\"测试集标签：\",set_test.test_labels.size())\n",
    "type(set_train[0]) #数据集的索引是tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SelfAttn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n(0 ,.,.) = \n  0  1  2\n  3  4  5\n  6  7  8\n[torch.FloatTensor of size 1x3x3]\n\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n(0 ,.,.) = \n  5.9996  6.9996  7.9996\n  6.0000  7.0000  8.0000\n  6.0000  7.0000  8.0000\n[torch.FloatTensor of size (1,3,3)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SelfAttn(nn.Module):\n",
    "    \"\"\"\n",
    "    自注意力层, softmax(x*x^T) * x\n",
    "    输入：x(batch,seq,dim)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SelfAttn, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        w = torch.bmm(x, x.permute(0, 2, 1))\n",
    "        w = F.softmax(w, dim=2)\n",
    "        return torch.bmm(w,x)\n",
    "    \n",
    "self_attn = SelfAttn()\n",
    "x = torch.arange(9).view(1,3,3)\n",
    "print(x)\n",
    "x = Variable(x)\n",
    "self_attn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LayerNormalization(nn.Module):\n",
    "    ''' \n",
    "    从transformer中复制过来的Layer normalization 模块\n",
    "    对倒数第一个维度执行归一化\n",
    "    输入的shape是[batch_size, seq_len, channel]\n",
    "    '''\n",
    "\n",
    "    def __init__(self, d_hid, eps=1e-3):\n",
    "        super(LayerNormalization, self).__init__()\n",
    "\n",
    "        self.eps = eps\n",
    "        self.a_2 = nn.Parameter(torch.ones(d_hid), requires_grad=True)\n",
    "        self.b_2 = nn.Parameter(torch.zeros(d_hid), requires_grad=True)\n",
    "\n",
    "    def forward(self, z):\n",
    "        if z.size(1) == 1:\n",
    "            return z\n",
    "\n",
    "        mu = torch.mean(z, keepdim=True, dim=-1)\n",
    "        sigma = torch.std(z, keepdim=True, dim=-1)\n",
    "        ln_out = (z - mu.expand_as(z)) / (sigma.expand_as(z) + self.eps)\n",
    "        ln_out = ln_out * self.a_2.expand_as(ln_out) + self.b_2.expand_as(ln_out)\n",
    "\n",
    "        return ln_out\n",
    "    \n",
    "class inConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(inConv, self).__init__()\n",
    "        pass\n",
    "    def forward(self, x):\n",
    "        return x.permute(0,2,1)\n",
    "    \n",
    "class outConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(outConv, self).__init__()\n",
    "        pass\n",
    "    def forward(self, x):\n",
    "        return x.permute(0,2,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构造模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, h_dim = 256):\n",
    "        super(Net, self).__init__()\n",
    "        self.subnet = nn.Sequential(\n",
    "            LayerNormalization(28),\n",
    "            inConv(),\n",
    "            nn.Conv1d(28,h_dim,1),\n",
    "            outConv(),\n",
    "            SelfAttn(),\n",
    "            \n",
    "            #LayerNormalization(h_dim),\n",
    "            #inConv(),\n",
    "            #nn.Conv1d(h_dim,h_dim,1),\n",
    "            #outConv(),\n",
    "            #SelfAttn(),\n",
    "            \n",
    "            #LayerNormalization(h_dim),\n",
    "            #inConv(),\n",
    "            #nn.Conv1d(h_dim,h_dim,1),\n",
    "            #outConv(),\n",
    "            #SelfAttn(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(28*h_dim,10),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        n = x.size(0)\n",
    "        out = self.subnet(x)\n",
    "        #print(out.shape)\n",
    "        out = out.view(n,-1)\n",
    "        #print(out.shape)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "net =Net().cuda()\n",
    "\n",
    "x = torch.randn(64, 28, 28).cuda() # batch,seq,dim\n",
    "x_var = Variable(x) \n",
    "\n",
    "net(x_var).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初始化一些参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is a little utility that we'll use to reset the model\n",
    "# if we want to re-initialize all our parameters\n",
    "def reset(m):\n",
    "    if hasattr(m, 'reset_parameters'):\n",
    "        m.reset_parameters()\n",
    "        \n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.size() # 读取 N, C, H, W\n",
    "        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "    \n",
    "def train(model, loss_fn, optimizer, num_epochs = 5, print_every = 200):\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
    "        check_accuracy(model, loader_test)\n",
    "        model.train()\n",
    "        loss_meter = meter.AverageValueMeter()\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            x_var = Variable(x.cuda())\n",
    "            x_var = x_var.squeeze()\n",
    "            #print(x_var.shape)\n",
    "            y_var = Variable(y.cuda().long())\n",
    "            scores = model(x_var)\n",
    "            \n",
    "            loss = loss_fn(scores, y_var)\n",
    "            loss_meter.add(loss.data[0])\n",
    "                   \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (t + 1) % print_every == 0:\n",
    "                print(\"t:{}:loss:{:.3}\".format(t,loss_meter.value()[0]))\n",
    "\n",
    "def check_accuracy(model, loader):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    with torch.no_grad(): \n",
    "        for x, y in loader:\n",
    "            x_var = Variable(x.cuda())\n",
    "            x_var = x_var.squeeze()\n",
    "            scores = model(x_var)\n",
    "            _, preds = scores.data.cpu().max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 20\nChecking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1416 / 10000 correct (14.16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 2 / 20\nChecking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 9077 / 10000 correct (90.77)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 3 / 20\nChecking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 9209 / 10000 correct (92.09)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 4 / 20\nChecking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 9276 / 10000 correct (92.76)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 5 / 20\nChecking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 9327 / 10000 correct (93.27)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 6 / 20\nChecking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 9349 / 10000 correct (93.49)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 7 / 20\nChecking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 9351 / 10000 correct (93.51)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 8 / 20\nChecking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 9347 / 10000 correct (93.47)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 9 / 20\nChecking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 9350 / 10000 correct (93.50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 10 / 20\nChecking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 9356 / 10000 correct (93.56)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 11 / 20\nChecking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 9346 / 10000 correct (93.46)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 12 / 20\nChecking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 9345 / 10000 correct (93.45)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 13 / 20\nChecking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 9357 / 10000 correct (93.57)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 14 / 20\nChecking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 9361 / 10000 correct (93.61)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 15 / 20\nChecking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 9345 / 10000 correct (93.45)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 16 / 20\nChecking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 9350 / 10000 correct (93.50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 17 / 20\nChecking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 9357 / 10000 correct (93.57)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 18 / 20\nChecking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 9345 / 10000 correct (93.45)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 19 / 20\nChecking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 9351 / 10000 correct (93.51)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 20 / 20\nChecking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 9347 / 10000 correct (93.47)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 9347 / 10000 correct (93.47)\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=1e-3, momentum=0.9)\n",
    "\n",
    "#torch.cuda.random.manual_seed(123)\n",
    "#Net.apply(reset) #重置权值\n",
    "train(net, loss_fn, optimizer, num_epochs=20)\n",
    "check_accuracy(net, loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# attention始终达不到很好的效果"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
